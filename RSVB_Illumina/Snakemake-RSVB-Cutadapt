### Author: Emily Bendall
### Purpose: Get consensus genomes from Illumina sequencing data.
### This is designed for using Primal Scheme primers for RSV on Illumina.

# ============================= How to run this pipeline ==========================

# 1. Modify the parameters below as needed ("rule parameters").
# 2. Load modules: module load Bioinformatics ivar python2.7-anaconda/2019.03 samtools/1.9 fastqc picard-tools bwa bedtools2 R
# 3. Copy fastq files to data/fastq.
# 4. Rename raw fastq files: python ~/variant_pipeline_resources/change_miseq_names_sars2.py -s data/fastq -f data/fastq_renamed -run
# 5. Unzip fastq files: gunzip -v data/fastq_renamed/*.gz
# 6. Activate snakemake: conda activate snakemake
# 7. Run job on Slurm: sbatch submit_snakemake.sbat -- Or run directly: snakemake -s Snakefile-BWA -p --latency-wait 30 --cores 2

# ============================= Configure run options here =============================

IDS, = glob_wildcards(config["run_name"]+"/data/fastq_renamed/{id}.1.fastq.gz") # Where the pipeline will grab all of the IDs to run. Important to have changed the filenames first.

rule all:
    input:
        expand(config["run_name"]+"/data/ivar_output/consensus/{id}.fa", id =IDS),
        config["run_name"]  + "/" + config["run_name"]+".90.consensus.fasta",
        config["run_name"]  + "/" + config["run_name"]+".full.consensus.fasta",
        config["run_name"] + "/" + config["run_name"]+".coverage.csv"
rule parameters:
    params:
        bed_file = "ivar_reference/RSVA_primer_scheme.bed",
        reference_fasta = "ivar_reference/EPI_ISL_1653999.fasta", # fasta used for alignment
        reference_index = "ivar_reference/EPI_ISL_1653999", # bwa index used for alignment. Should be a build of reference_fasta
        min_length = 13700, # minimum length of consensus genomes in final fasta file
        min_qual_score = 0, # minimum quality score used in iVar consensus. Important that this is zero for calling indels.
        consensus_threshold = 0, # frequency threshold value used in iVar consensus. See documentation.
        min_depth = 10, # minimum depth used in iVar consensus
        cutadapt_seq_fwd = "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA", # sequence used for adapter trimming. This is NEBnext (same as TruSeq). Nextera adapter sequence, forward and reverse: CTGTCTCTTATACACATCT
        cutadapt_seq_rev = "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT",
        Rprimer =  "ivar_reference/RSVB_Right_primer.fasta",
        Fprimer ="ivar_reference/RSVB_Left_primer.fasta"

setup = rules.parameters.params

# ============================= Here are the pipeline rules =============================

rule fastqc:
    message:
        """
        =======================================================
        Run FastQC
        =======================================================
        """
    input:
        reads_1_in = config["run_name"]+"/data/fastq_renamed/{id}.1.fastq.gz",
        reads_2_in = config["run_name"]+"/data/fastq_renamed/{id}.2.fastq.gz"
    output:
        output1 =config["run_name"]+"/data/aligned_output/fastqc/{id}.1_fastqc.zip",
        output2=config["run_name"]+"/data/aligned_output/fastqc/{id}.2_fastqc.zip"
    params:
    	config["run_name"]+"/data/aligned_output/fastqc"
    run:
        shell("fastqc -o {params} --noextract -f fastq {input.reads_1_in}")
        shell("fastqc -o {params} --noextract -f fastq {input.reads_2_in}")

rule cutadapt:
    message:
        """
        =======================================================
        Trim Primers- cutadapt
        =======================================================
        """
    input:
         read_1 = config["run_name"]+"/data/fastq_renamed/{id}.1.fastq.gz",
         read_2 = config["run_name"]+"/data/fastq_renamed/{id}.2.fastq.gz"
    output:
         read_1 = config["run_name"]+"/data/aligned_output/align/{id}.1.trimmed.fastq",
         read_2 = config["run_name"]+"/data/aligned_output/align/{id}.2.trimmed.fastq",
         primer_trim_1 = config["run_name"]+"/data/aligned_output/align/{id}.1.primertrimmed.fastq",
         primer_trim_2 = config["run_name"]+"/data/aligned_output/align/{id}.2.primertrimmed.fastq",

    shell:
        """
        cutadapt -a CTGTCTCTTATACACATCT -A CTGTCTCTTATACACATCT -q 25 -m 20 -o {output.read_1}  \
        -p  {output.read_2}  {input.read_1}  {input.read_2}

        cutadapt -a "file:{setup.Fprimer}" -g "file:{setup.Rprimer}" -o {output.primer_trim_1} \
        -p  {output.primer_trim_2} {output.read_1} {output.read_2}
        """

rule bwa_align:
    message:
        """
        =======================================================
        Map with BWA and sort
        =======================================================
        """
    input:
        reads_1_in = config["run_name"]+"/data/aligned_output/align/{id}.1.primertrimmed.fastq",
        reads_2_in = config["run_name"]+"/data/aligned_output/align/{id}.2.primertrimmed.fastq",
    output:
        bam = config["run_name"]+"/data/aligned_output/align/{id}.sorted.bam"
    shell:
        "bwa mem {setup.reference_index} {input.reads_1_in} {input.reads_2_in} | samtools view -F 4 -Sb | samtools sort -o {output.bam} && samtools index {output.bam}"


rule get_coverage:
    message:
        """
        =======================================================
        Get coverage with samtools
        =======================================================
        """
    input:
        config["run_name"]+"/data/aligned_output/align/{id}.sorted.bam"
    output:
        config["run_name"]+"/data/ivar_output/coverage/{id}.coverage.csv"
    shell:
        "samtools depth -a -d 100000 {input} > {output}"

rule get_consensus:
    message:
        """
        =======================================================
        Get the consensus sequence with iVar
        =======================================================
        """
    input:
        bam_file = config["run_name"]+"/data/aligned_output/align/{id}.sorted.bam"
    output:
        consensus_file = config["run_name"]+"/data/ivar_output/consensus/{id}.fa"
    shell:
        "samtools mpileup -a -A -d 100000 -Q 0 --reference {setup.reference_fasta} {input.bam_file} | ivar consensus -p {output.consensus_file} -n N -q {setup.min_qual_score} -t {setup.consensus_threshold} -m {setup.min_depth}"

rule combine_and_export:
    message:
        """
        =======================================================
        Combine into a single fasta and coverage file
        =======================================================
        """
    input:
        consensus_files = expand(config["run_name"]+"/data/ivar_output/consensus/{id}.fa", id = IDS),
        coverage_files = expand (config["run_name"]+"/data/ivar_output/coverage/{id}.coverage.csv", id =IDS)
    output:
        config["run_name"] + "/" + config["run_name"]+".90.consensus.fasta",
        config["run_name"]  + "/" + config["run_name"]+".full.consensus.fasta",
        config["run_name"] + "/" + config["run_name"]+".coverage.csv"
    params:
        config["run_name"]
    shell:
        "python ivar_CombineAndExport.py --run-name {params} --min-length {setup.min_length}"
